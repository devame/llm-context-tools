{
  "version": "2.0.0",
  "granularity": "function",
  "generated": "2026-01-09T05:19:35.286Z",
  "files": {
    "analyze.js": {
      "hash": "61293962ea41238d76d6c118408ab353",
      "size": 4054,
      "lastModified": "2025-12-02T06:19:35.946Z",
      "functions": [],
      "analysisTime": null,
      "functionHashes": {}
    },
    "bin/llm-context.js": {
      "hash": "cdd8d16822e9eb4d93a2f98795899685",
      "size": 5952,
      "lastModified": "2025-12-02T06:32:30.824Z",
      "functions": [],
      "analysisTime": null,
      "functionHashes": {
        "runScript": {
          "hash": "f75e11694dfd6a771762bed60e6d045f",
          "line": 23,
          "endLine": 40,
          "size": 468,
          "async": false,
          "source": "function runScript(scriptPath, extraArgs = []) {\r\n  const fullPath = join(rootDir, scriptPath);\r\n\r\n  if (!existsSync(fullPath)) {\r\n    console.error(`Error: Script not found: ${scriptPath}`);\r\n    process.exit(1);\r\n  }\r\n\r\n  try {\r\n    const allArgs = [...extraArgs, ...commandArgs].join(' ');\r\n    execSync(`node \"${fullPath}\" ${allArgs}`, {\r\n      stdio: 'inherit',\r\n      cwd: process.cwd()\r\n    });\r\n  } catch (error) {\r\n    process.exit(error.status || 1);\r\n  }\r\n}"
        }
      }
    },
    "change-detector.js": {
      "hash": "b8796ed5c3d57fff2390b0e3e60594a6",
      "size": 5929,
      "lastModified": "2025-12-02T06:19:35.953Z",
      "functions": [
        "findJsFiles",
        "walk",
        "loadManifest",
        "detectChanges",
        "printSummary",
        "main",
        "computeFileHash"
      ],
      "analysisTime": null,
      "functionHashes": {
        "hashFile": {
          "hash": "9e96f31965bab82be63fb83f2c462d10",
          "line": 23,
          "endLine": 27,
          "size": 156,
          "async": false,
          "source": "function hashFile(filePath) {\r\n  const content = readFileSync(filePath);\r\n  const hash = createHash('md5').update(content).digest('hex');\r\n  return hash;\r\n}"
        },
        "findJsFiles": {
          "hash": "89c99a1206f400d543a97c862b5ea524",
          "line": 35,
          "endLine": 59,
          "size": 672,
          "async": false,
          "source": "function findJsFiles(dir = '.', ignore = ['node_modules', '.git', '.llm-context']) {\r\n  const files = [];\r\n\r\n  function walk(currentDir) {\r\n    const entries = readdirSync(currentDir, { withFileTypes: true });\r\n\r\n    for (const entry of entries) {\r\n      const fullPath = join(currentDir, entry.name);\r\n      const relativePath = relative('.', fullPath);\r\n\r\n      if (ignore.some(pattern => relativePath.includes(pattern))) {\r\n        continue;\r\n      }\r\n\r\n      if (entry.isDirectory()) {\r\n        walk(fullPath);\r\n      } else if (entry.isFile() && entry.name.endsWith('.js')) {\r\n        files.push(relativePath);\r\n      }\r\n    }\r\n  }\r\n\r\n  walk(dir);\r\n  return files;\r\n}"
        },
        "walk": {
          "hash": "da39670806521944b417a2adc808b966",
          "line": 38,
          "endLine": 55,
          "size": 525,
          "async": false,
          "source": "function walk(currentDir) {\r\n    const entries = readdirSync(currentDir, { withFileTypes: true });\r\n\r\n    for (const entry of entries) {\r\n      const fullPath = join(currentDir, entry.name);\r\n      const relativePath = relative('.', fullPath);\r\n\r\n      if (ignore.some(pattern => relativePath.includes(pattern))) {\r\n        continue;\r\n      }\r\n\r\n      if (entry.isDirectory()) {\r\n        walk(fullPath);\r\n      } else if (entry.isFile() && entry.name.endsWith('.js')) {\r\n        files.push(relativePath);\r\n      }\r\n    }\r\n  }"
        },
        "loadManifest": {
          "hash": "0fc889c1a5882ebe921bbb0cacfb13a6",
          "line": 65,
          "endLine": 74,
          "size": 284,
          "async": false,
          "source": "function loadManifest() {\r\n  const manifestPath = '.llm-context/manifest.json';\r\n\r\n  if (!existsSync(manifestPath)) {\r\n    console.log('⚠ No manifest.json found - run manifest-generator.js first');\r\n    return null;\r\n  }\r\n\r\n  return JSON.parse(readFileSync(manifestPath, 'utf-8'));\r\n}"
        },
        "detectChanges": {
          "hash": "20380ed472521d85278bc6d6a40659af",
          "line": 80,
          "endLine": 153,
          "size": 2019,
          "async": false,
          "source": "function detectChanges() {\r\n  console.log('[1] Loading manifest...');\r\n  const manifest = loadManifest();\r\n\r\n  if (!manifest) {\r\n    return {\r\n      added: [],\r\n      modified: [],\r\n      deleted: [],\r\n      unchanged: [],\r\n      needsFullAnalysis: true\r\n    };\r\n  }\r\n\r\n  console.log(`    Last analysis: ${manifest.generated}`);\r\n  console.log(`    Files tracked: ${Object.keys(manifest.files).length}\\n`);\r\n\r\n  console.log('[2] Discovering current files...');\r\n  const currentFiles = findJsFiles();\r\n  console.log(`    Found ${currentFiles.length} JavaScript files\\n`);\r\n\r\n  console.log('[3] Computing changes...');\r\n\r\n  const manifestFiles = new Set(Object.keys(manifest.files));\r\n  const currentFilesSet = new Set(currentFiles);\r\n\r\n  const added = [];\r\n  const modified = [];\r\n  const deleted = [];\r\n  const unchanged = [];\r\n\r\n  // Check for new and modified files\r\n  for (const filePath of currentFiles) {\r\n    if (!manifestFiles.has(filePath)) {\r\n      // New file\r\n      added.push(filePath);\r\n      console.log(`    + ${filePath} (NEW)`);\r\n    } else {\r\n      // Existing file - check hash\r\n      const currentHash = hashFile(filePath);\r\n      const manifestHash = manifest.files[filePath].hash;\r\n\r\n      if (currentHash !== manifestHash) {\r\n        modified.push(filePath);\r\n        console.log(`    M ${filePath} (MODIFIED)`);\r\n        console.log(`      Old: ${manifestHash.substring(0, 12)}...`);\r\n        console.log(`      New: ${currentHash.substring(0, 12)}...`);\r\n      } else {\r\n        unchanged.push(filePath);\r\n      }\r\n    }\r\n  }\r\n\r\n  // Check for deleted files\r\n  for (const filePath of manifestFiles) {\r\n    if (!currentFilesSet.has(filePath)) {\r\n      deleted.push(filePath);\r\n      console.log(`    - ${filePath} (DELETED)`);\r\n    }\r\n  }\r\n\r\n  if (added.length === 0 && modified.length === 0 && deleted.length === 0) {\r\n    console.log('    ✓ No changes detected');\r\n  }\r\n\r\n  return {\r\n    added,\r\n    modified,\r\n    deleted,\r\n    unchanged,\r\n    needsFullAnalysis: false,\r\n    manifest\r\n  };\r\n}"
        },
        "printSummary": {
          "hash": "c50ef203bd585e3141e389bf006915b8",
          "line": 159,
          "endLine": 191,
          "size": 1333,
          "async": false,
          "source": "function printSummary(report) {\r\n  console.log('\\n=== Change Summary ===');\r\n\r\n  if (report.needsFullAnalysis) {\r\n    console.log('Status: Full analysis needed (no existing manifest)');\r\n    return;\r\n  }\r\n\r\n  const total = report.added.length + report.modified.length + report.deleted.length;\r\n\r\n  console.log(`Total files: ${report.added.length + report.modified.length + report.unchanged.length}`);\r\n  console.log(`Changes detected: ${total}`);\r\n  console.log(`  Added: ${report.added.length}`);\r\n  console.log(`  Modified: ${report.modified.length}`);\r\n  console.log(`  Deleted: ${report.deleted.length}`);\r\n  console.log(`  Unchanged: ${report.unchanged.length}`);\r\n\r\n  if (total === 0) {\r\n    console.log('\\n✓ All files up to date - no re-analysis needed!');\r\n  } else {\r\n    const percentChanged = ((total / (total + report.unchanged.length)) * 100).toFixed(1);\r\n    console.log(`\\nRe-analysis needed for ${total} files (${percentChanged}% of codebase)`);\r\n\r\n    // Estimate time savings\r\n    const unchangedCount = report.unchanged.length;\r\n    if (unchangedCount > 0) {\r\n      console.log(`\\nEstimated savings:`);\r\n      console.log(`  Files skipped: ${unchangedCount}`);\r\n      console.log(`  Approximate time saved: ${(unchangedCount * 0.5).toFixed(1)}s`);\r\n      console.log(`  (Assuming ~500ms per file)`);\r\n    }\r\n  }\r\n}"
        },
        "main": {
          "hash": "401ee1e744ad9394bd18e0b680e8107d",
          "line": 196,
          "endLine": 200,
          "size": 98,
          "async": false,
          "source": "function main() {\r\n  const report = detectChanges();\r\n  printSummary(report);\r\n  return report;\r\n}"
        }
      }
    },
    "dependency-analyzer.js": {
      "hash": "ba4d56e44a040a06c18f3bdc18d18c13",
      "size": 10937,
      "lastModified": "2025-12-02T06:19:35.953Z",
      "functions": [],
      "analysisTime": null,
      "functionHashes": {
        "loadConfig": {
          "hash": "8324daae1cd076e72a2cff6c009bc7ba",
          "line": 17,
          "endLine": 25,
          "size": 233,
          "async": false,
          "source": "function loadConfig() {\r\n  const configPath = './llm-context.config.json';\r\n\r\n  if (!existsSync(configPath)) {\r\n    return { analysis: { trackDependencies: false } };\r\n  }\r\n\r\n  return JSON.parse(readFileSync(configPath, 'utf-8'));\r\n}"
        },
        "loadGraph": {
          "hash": "8521ff896fb3da800c1313f00fe1dcb5",
          "line": 31,
          "endLine": 40,
          "size": 258,
          "async": false,
          "source": "function loadGraph() {\r\n  const graphPath = '.llm-context/graph.jsonl';\r\n\r\n  if (!existsSync(graphPath)) {\r\n    return [];\r\n  }\r\n\r\n  const lines = readFileSync(graphPath, 'utf-8').split('\\n').filter(Boolean);\r\n  return lines.map(line => JSON.parse(line));\r\n}"
        },
        "buildDependencyGraph": {
          "hash": "a79b75dc5a094a3a0bd54b71f75f2418",
          "line": 47,
          "endLine": 79,
          "size": 1033,
          "async": false,
          "source": "function buildDependencyGraph(functions) {\r\n  const dependencies = new Map(); // function -> functions it depends on\r\n  const dependents = new Map();   // function -> functions that depend on it\r\n  const functionMap = new Map();  // name -> full entry\r\n\r\n  // Index functions by name\r\n  for (const func of functions) {\r\n    const name = func.name || func.id;\r\n    functionMap.set(name, func);\r\n    dependencies.set(name, new Set());\r\n    dependents.set(name, new Set());\r\n  }\r\n\r\n  // Build dependency relationships\r\n  for (const func of functions) {\r\n    const name = func.name || func.id;\r\n    const calls = func.calls || [];\r\n\r\n    for (const calledName of calls) {\r\n      // Only track dependencies to functions we know about\r\n      if (functionMap.has(calledName)) {\r\n        dependencies.get(name).add(calledName);\r\n        dependents.get(calledName).add(name);\r\n      }\r\n    }\r\n  }\r\n\r\n  return {\r\n    dependencies,  // what each function depends on\r\n    dependents,    // what depends on each function\r\n    functionMap\r\n  };\r\n}"
        },
        "computeImpactSet": {
          "hash": "084d1f78d9d6434a7ba0aa5f8cf24bda",
          "line": 88,
          "endLine": 116,
          "size": 718,
          "async": false,
          "source": "function computeImpactSet(functionName, dependents, maxDepth = 10) {\r\n  const impacted = new Set();\r\n  const queue = [[functionName, 0]]; // [name, depth]\r\n  const visited = new Set();\r\n\r\n  while (queue.length > 0) {\r\n    const [current, depth] = queue.shift();\r\n\r\n    if (visited.has(current) || depth > maxDepth) {\r\n      continue;\r\n    }\r\n\r\n    visited.add(current);\r\n\r\n    if (current !== functionName) {\r\n      impacted.add(current);\r\n    }\r\n\r\n    // Add all functions that depend on current\r\n    const deps = dependents.get(current) || new Set();\r\n    for (const dependent of deps) {\r\n      if (!visited.has(dependent)) {\r\n        queue.push([dependent, depth + 1]);\r\n      }\r\n    }\r\n  }\r\n\r\n  return impacted;\r\n}"
        },
        "findEntryPoints": {
          "hash": "693d1692424f0dbb3444002651ab5930",
          "line": 124,
          "endLine": 140,
          "size": 459,
          "async": false,
          "source": "function findEntryPoints(dependents, maxCallers = 2) {\r\n  const entryPoints = [];\r\n\r\n  for (const [funcName, callers] of dependents) {\r\n    if (callers.size <= maxCallers ||\r\n        funcName.includes('main') ||\r\n        funcName.includes('init') ||\r\n        funcName.includes('start')) {\r\n      entryPoints.push({\r\n        name: funcName,\r\n        callers: callers.size\r\n      });\r\n    }\r\n  }\r\n\r\n  return entryPoints.sort((a, b) => a.callers - b.callers);\r\n}"
        },
        "findLeafFunctions": {
          "hash": "a73c3fbb14e5546501a1d815f24bbe8b",
          "line": 147,
          "endLine": 157,
          "size": 209,
          "async": false,
          "source": "function findLeafFunctions(dependencies) {\r\n  const leaves = [];\r\n\r\n  for (const [funcName, deps] of dependencies) {\r\n    if (deps.size === 0) {\r\n      leaves.push(funcName);\r\n    }\r\n  }\r\n\r\n  return leaves;\r\n}"
        },
        "detectCycles": {
          "hash": "b1bba446d43ddb4717c6270f3db306be",
          "line": 164,
          "endLine": 203,
          "size": 892,
          "async": false,
          "source": "function detectCycles(dependencies) {\r\n  const cycles = [];\r\n  const visited = new Set();\r\n  const recursionStack = new Set();\r\n  const path = [];\r\n\r\n  function dfs(node) {\r\n    visited.add(node);\r\n    recursionStack.add(node);\r\n    path.push(node);\r\n\r\n    const deps = dependencies.get(node) || new Set();\r\n\r\n    for (const dep of deps) {\r\n      if (!visited.has(dep)) {\r\n        if (dfs(dep)) {\r\n          return true;\r\n        }\r\n      } else if (recursionStack.has(dep)) {\r\n        // Found cycle\r\n        const cycleStart = path.indexOf(dep);\r\n        const cycle = path.slice(cycleStart);\r\n        cycle.push(dep); // Close the cycle\r\n        cycles.push(cycle);\r\n      }\r\n    }\r\n\r\n    path.pop();\r\n    recursionStack.delete(node);\r\n    return false;\r\n  }\r\n\r\n  for (const node of dependencies.keys()) {\r\n    if (!visited.has(node)) {\r\n      dfs(node);\r\n    }\r\n  }\r\n\r\n  return cycles;\r\n}"
        },
        "dfs": {
          "hash": "fbf2ed9aed25aad330749c339be072bf",
          "line": 214,
          "endLine": 233,
          "size": 429,
          "async": false,
          "source": "function dfs(node, depth) {\r\n    if (visited.has(node)) {\r\n      return 0; // Avoid cycles\r\n    }\r\n\r\n    visited.add(node);\r\n\r\n    const deps = dependencies.get(node) || new Set();\r\n    if (deps.size === 0) {\r\n      return depth;\r\n    }\r\n\r\n    let maxDepth = depth;\r\n    for (const dep of deps) {\r\n      const childDepth = dfs(dep, depth + 1);\r\n      maxDepth = Math.max(maxDepth, childDepth);\r\n    }\r\n\r\n    return maxDepth;\r\n  }"
        },
        "computeDependencyDepth": {
          "hash": "2331d748e2559fcde765560ea9442688",
          "line": 211,
          "endLine": 236,
          "size": 563,
          "async": false,
          "source": "function computeDependencyDepth(functionName, dependencies) {\r\n  const visited = new Set();\r\n\r\n  function dfs(node, depth) {\r\n    if (visited.has(node)) {\r\n      return 0; // Avoid cycles\r\n    }\r\n\r\n    visited.add(node);\r\n\r\n    const deps = dependencies.get(node) || new Set();\r\n    if (deps.size === 0) {\r\n      return depth;\r\n    }\r\n\r\n    let maxDepth = depth;\r\n    for (const dep of deps) {\r\n      const childDepth = dfs(dep, depth + 1);\r\n      maxDepth = Math.max(maxDepth, childDepth);\r\n    }\r\n\r\n    return maxDepth;\r\n  }\r\n\r\n  return dfs(functionName, 0);\r\n}"
        },
        "analyzeDependencies": {
          "hash": "82a7c7400e8082356f76940d35c1e411",
          "line": 241,
          "endLine": 324,
          "size": 2837,
          "async": false,
          "source": "function analyzeDependencies() {\r\n  console.log('=== Dependency Analyzer ===\\n');\r\n\r\n  const config = loadConfig();\r\n  const trackDeps = config.analysis?.trackDependencies || false;\r\n\r\n  if (!trackDeps) {\r\n    console.log('Dependency tracking disabled in config');\r\n    console.log('Set analysis.trackDependencies = true to enable');\r\n    return null;\r\n  }\r\n\r\n  const functions = loadGraph();\r\n  console.log(`[1] Loaded ${functions.length} functions from graph\\n`);\r\n\r\n  const { dependencies, dependents, functionMap } = buildDependencyGraph(functions);\r\n  console.log(`[2] Built dependency graph`);\r\n  console.log(`    Total dependencies: ${Array.from(dependencies.values()).reduce((sum, deps) => sum + deps.size, 0)}\\n`);\r\n\r\n  // Find entry points\r\n  const entryPoints = findEntryPoints(dependents);\r\n  console.log(`[3] Entry points (${entryPoints.length}):`);\r\n  for (const ep of entryPoints.slice(0, 10)) {\r\n    console.log(`    - ${ep.name} (${ep.callers} callers)`);\r\n  }\r\n  if (entryPoints.length > 10) {\r\n    console.log(`    ... and ${entryPoints.length - 10} more`);\r\n  }\r\n\r\n  // Find leaf functions\r\n  const leaves = findLeafFunctions(dependencies);\r\n  console.log(`\\n[4] Leaf functions (${leaves.length}):`);\r\n  console.log(`    ${leaves.slice(0, 20).join(', ')}`);\r\n  if (leaves.length > 20) {\r\n    console.log(`    ... and ${leaves.length - 20} more`);\r\n  }\r\n\r\n  // Detect cycles\r\n  const cycles = detectCycles(dependencies);\r\n  if (cycles.length > 0) {\r\n    console.log(`\\n[5] ⚠ Dependency cycles detected (${cycles.length}):`);\r\n    for (const cycle of cycles.slice(0, 5)) {\r\n      console.log(`    ${cycle.join(' → ')}`);\r\n    }\r\n    if (cycles.length > 5) {\r\n      console.log(`    ... and ${cycles.length - 5} more`);\r\n    }\r\n  } else {\r\n    console.log(`\\n[5] ✓ No dependency cycles detected`);\r\n  }\r\n\r\n  // Save dependency graph\r\n  const depGraph = {\r\n    version: '1.0.0',\r\n    generated: new Date().toISOString(),\r\n    stats: {\r\n      totalFunctions: functions.length,\r\n      totalDependencies: Array.from(dependencies.values()).reduce((sum, deps) => sum + deps.size, 0),\r\n      entryPoints: entryPoints.length,\r\n      leafFunctions: leaves.length,\r\n      cycles: cycles.length\r\n    },\r\n    entryPoints,\r\n    leaves,\r\n    cycles,\r\n    dependencies: Object.fromEntries(\r\n      Array.from(dependencies.entries()).map(([name, deps]) => [\r\n        name,\r\n        Array.from(deps)\r\n      ])\r\n    ),\r\n    dependents: Object.fromEntries(\r\n      Array.from(dependents.entries()).map(([name, deps]) => [\r\n        name,\r\n        Array.from(deps)\r\n      ])\r\n    )\r\n  };\r\n\r\n  writeFileSync('.llm-context/dependencies.json', JSON.stringify(depGraph, null, 2));\r\n  console.log(`\\n✓ Dependency graph saved to .llm-context/dependencies.json`);\r\n\r\n  return { dependencies, dependents, functionMap, cycles, entryPoints, leaves };\r\n}"
        },
        "analyzeImpact": {
          "hash": "e4ae24d43fb29831f16f37329756d707",
          "line": 331,
          "endLine": 377,
          "size": 1571,
          "async": false,
          "source": "function analyzeImpact(changedFunctions) {\r\n  const functions = loadGraph();\r\n  const { dependencies, dependents, functionMap } = buildDependencyGraph(functions);\r\n\r\n  const config = loadConfig();\r\n  const maxDepth = config.analysis?.maxCallDepth || 10;\r\n\r\n  const impactReport = {\r\n    changedFunctions,\r\n    totalImpacted: new Set(),\r\n    perFunctionImpact: {}\r\n  };\r\n\r\n  console.log('\\n=== Impact Analysis ===\\n');\r\n\r\n  for (const funcName of changedFunctions) {\r\n    const impacted = computeImpactSet(funcName, dependents, maxDepth);\r\n\r\n    impactReport.perFunctionImpact[funcName] = {\r\n      directCallers: Array.from(dependents.get(funcName) || new Set()),\r\n      totalImpacted: impacted.size,\r\n      impactedFunctions: Array.from(impacted)\r\n    };\r\n\r\n    // Add to total impacted set\r\n    for (const imp of impacted) {\r\n      impactReport.totalImpacted.add(imp);\r\n    }\r\n\r\n    console.log(`${funcName}:`);\r\n    console.log(`  Direct callers: ${impactReport.perFunctionImpact[funcName].directCallers.length}`);\r\n    console.log(`  Total impacted: ${impacted.size}`);\r\n\r\n    if (impacted.size > 0 && impacted.size <= 10) {\r\n      console.log(`  Affected functions: ${Array.from(impacted).join(', ')}`);\r\n    } else if (impacted.size > 10) {\r\n      console.log(`  Affected functions: ${Array.from(impacted).slice(0, 10).join(', ')}...`);\r\n    }\r\n\r\n    console.log('');\r\n  }\r\n\r\n  impactReport.totalImpacted = Array.from(impactReport.totalImpacted);\r\n  console.log(`Total unique functions impacted: ${impactReport.totalImpacted.length}\\n`);\r\n\r\n  return impactReport;\r\n}"
        }
      }
    },
    "function-change-detector.js": {
      "hash": "eb260344062fadb49a6692d69071d6e5",
      "size": 9193,
      "lastModified": "2025-12-02T06:19:35.964Z",
      "functions": [
        "loadConfig",
        "extractCurrentFunctions",
        "detectFunctionChanges",
        "detectAllFunctionChanges",
        "printFunctionChangeSummary"
      ],
      "analysisTime": null,
      "functionHashes": {
        "loadConfig": {
          "hash": "df76c1763901b8b276b265bd5f5ee6d5",
          "line": 18,
          "endLine": 26,
          "size": 214,
          "async": false,
          "source": "function loadConfig() {\r\n  const configPath = './llm-context.config.json';\r\n\r\n  if (!existsSync(configPath)) {\r\n    return { granularity: 'file' };\r\n  }\r\n\r\n  return JSON.parse(readFileSync(configPath, 'utf-8'));\r\n}"
        },
        "extractCurrentFunctions": {
          "hash": "0d7d72a122df746c1b8ad624a08a0bb0",
          "line": 33,
          "endLine": 66,
          "size": 951,
          "async": false,
          "source": "function extractCurrentFunctions(filePath) {\r\n  const functionMap = new Map();\r\n\r\n  try {\r\n    const source = readFileSync(filePath, 'utf-8');\r\n\r\n    // Parse with Babel\r\n    const ast = parse(source, {\r\n      sourceType: 'module',\r\n      plugins: []\r\n    });\r\n\r\n    // Collect all functions\r\n    traverse.default(ast, {\r\n      FunctionDeclaration(path) {\r\n        const metadata = extractFunctionMetadata(path, source, filePath);\r\n        functionMap.set(metadata.name, metadata);\r\n      },\r\n\r\n      VariableDeclarator(path) {\r\n        if (path.node.init?.type === 'ArrowFunctionExpression' ||\r\n            path.node.init?.type === 'FunctionExpression') {\r\n          const metadata = extractFunctionMetadata(path, source, filePath);\r\n          functionMap.set(metadata.name, metadata);\r\n        }\r\n      }\r\n    });\r\n\r\n  } catch (error) {\r\n    console.log(`    Warning: Could not parse ${filePath}: ${error.message}`);\r\n  }\r\n\r\n  return functionMap;\r\n}"
        },
        "detectFunctionChanges": {
          "hash": "075d502608d6b7afcb16061caa138ced",
          "line": 74,
          "endLine": 189,
          "size": 3610,
          "async": true,
          "source": "async function detectFunctionChanges(filePath, manifest) {\r\n  const changes = {\r\n    filePath,\r\n    added: [],\r\n    modified: [],\r\n    deleted: [],\r\n    unchanged: [],\r\n    renames: []\r\n  };\r\n\r\n  // Get current functions\r\n  const currentFunctions = extractCurrentFunctions(filePath);\r\n\r\n  // Get manifest functions\r\n  const fileEntry = manifest.files[filePath];\r\n  if (!fileEntry || !fileEntry.functionHashes) {\r\n    // No previous function data - all current functions are \"added\"\r\n    for (const [name, metadata] of currentFunctions) {\r\n      changes.added.push({\r\n        name,\r\n        hash: metadata.hash,\r\n        line: metadata.line,\r\n        size: metadata.size\r\n      });\r\n    }\r\n    return changes;\r\n  }\r\n\r\n  const manifestFunctions = fileEntry.functionHashes;\r\n\r\n  // Compare current vs manifest\r\n  for (const [name, metadata] of currentFunctions) {\r\n    const manifestFunc = manifestFunctions[name];\r\n\r\n    if (!manifestFunc) {\r\n      // New function\r\n      changes.added.push({\r\n        name,\r\n        hash: metadata.hash,\r\n        line: metadata.line,\r\n        size: metadata.size\r\n      });\r\n    } else if (manifestFunc.hash !== metadata.hash) {\r\n      // Modified function\r\n      changes.modified.push({\r\n        name,\r\n        oldHash: manifestFunc.hash,\r\n        newHash: metadata.hash,\r\n        oldLine: manifestFunc.line,\r\n        newLine: metadata.line,\r\n        sizeDelta: metadata.size - manifestFunc.size\r\n      });\r\n    } else {\r\n      // Unchanged function\r\n      changes.unchanged.push(name);\r\n    }\r\n  }\r\n\r\n  // Find deleted functions\r\n  for (const name in manifestFunctions) {\r\n    if (!currentFunctions.has(name)) {\r\n      changes.deleted.push({\r\n        name,\r\n        hash: manifestFunctions[name].hash,\r\n        line: manifestFunctions[name].line\r\n      });\r\n    }\r\n  }\r\n\r\n  // Detect potential renames (deleted + added with similar code)\r\n  if (changes.deleted.length > 0 && changes.added.length > 0) {\r\n    const config = loadConfig();\r\n    const detectRenames = config.incremental?.detectRenames || false;\r\n\r\n    if (detectRenames && fileEntry.functionHashes) {\r\n      // Check if we have source stored for similarity comparison\r\n      const hasStoredSource = Object.values(fileEntry.functionHashes).some(f => f.source);\r\n\r\n      if (hasStoredSource) {\r\n        const { computeSimilarity } = await import('./function-source-extractor.js');\r\n        const threshold = config.incremental?.similarityThreshold || 0.85;\r\n\r\n        for (const deletedFunc of changes.deleted) {\r\n          const oldSource = manifestFunctions[deletedFunc.name]?.source;\r\n\r\n          if (!oldSource) continue;\r\n\r\n          // Compare with each added function\r\n          for (const addedFunc of changes.added) {\r\n            const newMetadata = currentFunctions.get(addedFunc.name);\r\n            if (!newMetadata || !newMetadata.source) continue;\r\n\r\n            const similarity = computeSimilarity(oldSource, newMetadata.source);\r\n\r\n            if (similarity >= threshold) {\r\n              changes.renames.push({\r\n                from: deletedFunc.name,\r\n                to: addedFunc.name,\r\n                similarity: similarity.toFixed(3),\r\n                oldLine: deletedFunc.line,\r\n                newLine: addedFunc.line\r\n              });\r\n\r\n              // Remove from deleted and added since it's a rename\r\n              changes.deleted = changes.deleted.filter(f => f.name !== deletedFunc.name);\r\n              changes.added = changes.added.filter(f => f.name !== addedFunc.name);\r\n              break;\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  return changes;\r\n}"
        },
        "detectAllFunctionChanges": {
          "hash": "e9b2ce6bd30fe1771446187815fb14f6",
          "line": 197,
          "endLine": 213,
          "size": 527,
          "async": true,
          "source": "async function detectAllFunctionChanges(changedFiles, manifest) {\r\n  const allChanges = new Map();\r\n\r\n  for (const filePath of changedFiles) {\r\n    const changes = await detectFunctionChanges(filePath, manifest);\r\n\r\n    // Only include files with actual function changes\r\n    if (changes.added.length > 0 ||\r\n        changes.modified.length > 0 ||\r\n        changes.deleted.length > 0 ||\r\n        (changes.renames && changes.renames.length > 0)) {\r\n      allChanges.set(filePath, changes);\r\n    }\r\n  }\r\n\r\n  return allChanges;\r\n}"
        },
        "printFunctionChangeSummary": {
          "hash": "39b2bd4ff089e1fd4437eb10a8a82f02",
          "line": 219,
          "endLine": 288,
          "size": 2599,
          "async": false,
          "source": "function printFunctionChangeSummary(functionChanges) {\r\n  let totalAdded = 0;\r\n  let totalModified = 0;\r\n  let totalDeleted = 0;\r\n  let totalRenamed = 0;\r\n  let totalUnchanged = 0;\r\n\r\n  console.log('\\n=== Function-Level Changes ===\\n');\r\n\r\n  for (const [filePath, changes] of functionChanges) {\r\n    console.log(`${filePath}:`);\r\n\r\n    if (changes.renames && changes.renames.length > 0) {\r\n      console.log(`  Renamed (${changes.renames.length}):`);\r\n      for (const rename of changes.renames) {\r\n        console.log(`    ≈ ${rename.from} → ${rename.to} (${(rename.similarity * 100).toFixed(1)}% similar, line ${rename.oldLine}→${rename.newLine})`);\r\n      }\r\n      totalRenamed += changes.renames.length;\r\n    }\r\n\r\n    if (changes.added.length > 0) {\r\n      console.log(`  Added (${changes.added.length}):`);\r\n      for (const func of changes.added) {\r\n        console.log(`    + ${func.name} (line ${func.line}, ${func.size} bytes)`);\r\n      }\r\n      totalAdded += changes.added.length;\r\n    }\r\n\r\n    if (changes.modified.length > 0) {\r\n      console.log(`  Modified (${changes.modified.length}):`);\r\n      for (const func of changes.modified) {\r\n        const delta = func.sizeDelta >= 0 ? `+${func.sizeDelta}` : `${func.sizeDelta}`;\r\n        console.log(`    ~ ${func.name} (line ${func.oldLine}→${func.newLine}, ${delta} bytes)`);\r\n      }\r\n      totalModified += changes.modified.length;\r\n    }\r\n\r\n    if (changes.deleted.length > 0) {\r\n      console.log(`  Deleted (${changes.deleted.length}):`);\r\n      for (const func of changes.deleted) {\r\n        console.log(`    - ${func.name} (was line ${func.line})`);\r\n      }\r\n      totalDeleted += changes.deleted.length;\r\n    }\r\n\r\n    if (changes.unchanged.length > 0) {\r\n      console.log(`  Unchanged: ${changes.unchanged.length} functions`);\r\n      totalUnchanged += changes.unchanged.length;\r\n    }\r\n\r\n    console.log('');\r\n  }\r\n\r\n  console.log('=== Summary ===');\r\n  if (totalRenamed > 0) {\r\n    console.log(`Total functions renamed: ${totalRenamed}`);\r\n  }\r\n  console.log(`Total functions added: ${totalAdded}`);\r\n  console.log(`Total functions modified: ${totalModified}`);\r\n  console.log(`Total functions deleted: ${totalDeleted}`);\r\n  console.log(`Total functions unchanged: ${totalUnchanged}`);\r\n\r\n  const totalChanged = totalAdded + totalModified + totalDeleted + totalRenamed;\r\n  const totalFunctions = totalChanged + totalUnchanged;\r\n  const percentUnchanged = totalFunctions > 0\r\n    ? ((totalUnchanged / totalFunctions) * 100).toFixed(1)\r\n    : 0;\r\n\r\n  console.log(`\\n✓ Efficiency: ${percentUnchanged}% of functions skipped!`);\r\n}"
        }
      }
    },
    "function-source-extractor.js": {
      "hash": "23baae78c3f55d92987c5763c0c6fb00",
      "size": 4877,
      "lastModified": "2025-12-02T06:19:35.964Z",
      "functions": [],
      "analysisTime": null,
      "functionHashes": {
        "extractFunctionSource": {
          "hash": "15a438d0ef62a870463de67a6fce3532",
          "line": 17,
          "endLine": 43,
          "size": 764,
          "async": false,
          "source": "function extractFunctionSource(path, sourceCode) {\r\n  const { start, end } = path.node.loc;\r\n\r\n  if (!start || !end) {\r\n    return '';\r\n  }\r\n\r\n  const lines = sourceCode.split('\\n');\r\n\r\n  // Extract lines from start.line to end.line (1-indexed)\r\n  const funcLines = lines.slice(start.line - 1, end.line);\r\n\r\n  // Handle single-line functions\r\n  if (funcLines.length === 1) {\r\n    return funcLines[0].substring(start.column, end.column);\r\n  }\r\n\r\n  // Multi-line functions\r\n  // First line: from start.column to end\r\n  funcLines[0] = funcLines[0].substring(start.column);\r\n\r\n  // Last line: from beginning to end.column\r\n  const lastIdx = funcLines.length - 1;\r\n  funcLines[lastIdx] = funcLines[lastIdx].substring(0, end.column);\r\n\r\n  return funcLines.join('\\n');\r\n}"
        },
        "hashFunctionSource": {
          "hash": "c58095851b6575484c4729270b2f0b99",
          "line": 50,
          "endLine": 57,
          "size": 269,
          "async": false,
          "source": "function hashFunctionSource(source) {\r\n  // Normalize whitespace to avoid spurious changes from reformatting\r\n  const normalized = source\r\n    .replace(/\\s+/g, ' ')  // Collapse whitespace\r\n    .trim();\r\n\r\n  return createHash('md5').update(normalized).digest('hex');\r\n}"
        },
        "generateFunctionId": {
          "hash": "7c0492931edf72b387002a81fa3744ec",
          "line": 66,
          "endLine": 73,
          "size": 233,
          "async": false,
          "source": "function generateFunctionId(filePath, funcName, line) {\r\n  // For anonymous functions, use line number\r\n  if (!funcName || funcName === 'anonymous') {\r\n    return `${filePath}#L${line}`;\r\n  }\r\n\r\n  return `${filePath}#${funcName}`;\r\n}"
        },
        "extractFunctionMetadata": {
          "hash": "14a241dfaa98a6e32d9d22728518eff2",
          "line": 82,
          "endLine": 115,
          "size": 864,
          "async": false,
          "source": "function extractFunctionMetadata(path, sourceCode, filePath) {\r\n  const node = path.node;\r\n\r\n  // Get function name\r\n  let funcName = 'anonymous';\r\n  if (node.id?.name) {\r\n    funcName = node.id.name;\r\n  } else if (path.parent?.type === 'VariableDeclarator' && path.parent.id?.name) {\r\n    funcName = path.parent.id.name;\r\n  }\r\n\r\n  // Extract source\r\n  const source = extractFunctionSource(path, sourceCode);\r\n  const hash = hashFunctionSource(source);\r\n\r\n  // Get location\r\n  const line = node.loc?.start.line || 0;\r\n  const endLine = node.loc?.end.line || 0;\r\n\r\n  // Generate unique ID\r\n  const funcId = generateFunctionId(filePath, funcName, line);\r\n\r\n  return {\r\n    id: funcId,\r\n    name: funcName,\r\n    line,\r\n    endLine,\r\n    source,\r\n    hash,\r\n    size: source.length,\r\n    isAsync: node.async || false,\r\n    isGenerator: node.generator || false\r\n  };\r\n}"
        },
        "computeSimilarity": {
          "hash": "fd0e75623233e33160750947ef74af55",
          "line": 123,
          "endLine": 142,
          "size": 598,
          "async": false,
          "source": "function computeSimilarity(source1, source2) {\r\n  // Simple similarity: compare normalized versions\r\n  const norm1 = source1.replace(/\\s+/g, ' ').trim();\r\n  const norm2 = source2.replace(/\\s+/g, ' ').trim();\r\n\r\n  if (norm1 === norm2) return 1.0;\r\n\r\n  // Levenshtein distance would be better, but this is simple\r\n  const maxLen = Math.max(norm1.length, norm2.length);\r\n  if (maxLen === 0) return 1.0;\r\n\r\n  let matches = 0;\r\n  const minLen = Math.min(norm1.length, norm2.length);\r\n\r\n  for (let i = 0; i < minLen; i++) {\r\n    if (norm1[i] === norm2[i]) matches++;\r\n  }\r\n\r\n  return matches / maxLen;\r\n}"
        },
        "detectRename": {
          "hash": "a88944da2979e00483235fa55fbd2230",
          "line": 151,
          "endLine": 169,
          "size": 455,
          "async": false,
          "source": "function detectRename(deletedFunc, addedFuncs, threshold = 0.9) {\r\n  let bestMatch = null;\r\n  let bestScore = threshold;\r\n\r\n  for (const addedFunc of addedFuncs) {\r\n    const score = computeSimilarity(deletedFunc.source, addedFunc.source);\r\n\r\n    if (score > bestScore) {\r\n      bestScore = score;\r\n      bestMatch = {\r\n        from: deletedFunc.name,\r\n        to: addedFunc.name,\r\n        similarity: score\r\n      };\r\n    }\r\n  }\r\n\r\n  return bestMatch;\r\n}"
        }
      }
    },
    "incremental-analyzer.js": {
      "hash": "e34702e6df27e461378a0fa42520f920",
      "size": 23415,
      "lastModified": "2026-01-09T05:19:02.266Z",
      "functions": [
        "computeFileHash",
        "getFileMetadata",
        "analyzeSingleFile",
        "loadGraph",
        "updateGraph",
        "updateManifest",
        "main"
      ],
      "analysisTime": null,
      "functionHashes": {
        "loadConfig": {
          "hash": "df76c1763901b8b276b265bd5f5ee6d5",
          "line": 27,
          "endLine": 35,
          "size": 214,
          "async": false,
          "source": "function loadConfig() {\r\n  const configPath = './llm-context.config.json';\r\n\r\n  if (!existsSync(configPath)) {\r\n    return { granularity: 'file' };\r\n  }\r\n\r\n  return JSON.parse(readFileSync(configPath, 'utf-8'));\r\n}"
        },
        "computeFileHash": {
          "hash": "b4700116aae3e5fd58d1b945f2ab7428",
          "line": 40,
          "endLine": 43,
          "size": 141,
          "async": false,
          "source": "function computeFileHash(filePath) {\r\n  const content = readFileSync(filePath);\r\n  return createHash('md5').update(content).digest('hex');\r\n}"
        },
        "getFileMetadata": {
          "hash": "033c4d4618e3789932d03e568030b192",
          "line": 48,
          "endLine": 54,
          "size": 162,
          "async": false,
          "source": "function getFileMetadata(filePath) {\r\n  const stats = statSync(filePath);\r\n  return {\r\n    size: stats.size,\r\n    lastModified: stats.mtime.toISOString()\r\n  };\r\n}"
        },
        "analyzeSpecificFunctions": {
          "hash": "04ad2cb0cb3d92f5d4a3273da6a09f4d",
          "line": 62,
          "endLine": 221,
          "size": 5370,
          "async": false,
          "source": "function analyzeSpecificFunctions(sourcePath, targetFunctions = null) {\r\n  const startTime = Date.now();\r\n  const source = readFileSync(sourcePath, 'utf-8');\r\n\r\n  // Parse with Babel\r\n  const ast = parse(source, {\r\n    sourceType: 'module',\r\n    plugins: []\r\n  });\r\n\r\n  const allFunctions = [];\r\n  const callGraph = new Map();\r\n  const sideEffects = new Map();\r\n\r\n  // First pass: collect all functions\r\n  traverse.default(ast, {\r\n    FunctionDeclaration(path) {\r\n      const metadata = extractFunctionMetadata(path, source, sourcePath);\r\n      allFunctions.push({ metadata, path });\r\n    },\r\n\r\n    VariableDeclarator(path) {\r\n      if (path.node.init?.type === 'ArrowFunctionExpression' ||\r\n          path.node.init?.type === 'FunctionExpression') {\r\n        const metadata = extractFunctionMetadata(path, source, sourcePath);\r\n        allFunctions.push({ metadata, path });\r\n      }\r\n    }\r\n  });\r\n\r\n  // Filter to target functions if specified\r\n  const functionsToAnalyze = targetFunctions\r\n    ? allFunctions.filter(f => targetFunctions.includes(f.metadata.name))\r\n    : allFunctions;\r\n\r\n  // Second pass: analyze function bodies\r\n  const results = [];\r\n\r\n  for (const { metadata, path } of functionsToAnalyze) {\r\n    const funcId = metadata.id;\r\n    callGraph.set(funcId, []);\r\n    sideEffects.set(funcId, []);\r\n\r\n    // Analyze calls and side effects\r\n    path.traverse({\r\n      CallExpression(callPath) {\r\n        const callee = callPath.node.callee;\r\n        let calledName = '';\r\n\r\n        if (callee.type === 'Identifier') {\r\n          calledName = callee.name;\r\n        } else if (callee.type === 'MemberExpression') {\r\n          const obj = callee.object.name || '';\r\n          const prop = callee.property.name || '';\r\n          calledName = obj ? `${obj}.${prop}` : prop;\r\n        }\r\n\r\n        if (calledName) {\r\n          const calls = callGraph.get(funcId) || [];\r\n          calls.push(calledName);\r\n          callGraph.set(funcId, calls);\r\n\r\n          // Detect side effects\r\n          const effects = sideEffects.get(funcId) || [];\r\n\r\n          if (/read|write|append|unlink|mkdir|rmdir|fs\\./i.test(calledName)) {\r\n            effects.push({ type: 'file_io', at: calledName });\r\n          }\r\n          if (/fetch|request|axios|http|socket/i.test(calledName)) {\r\n            effects.push({ type: 'network', at: calledName });\r\n          }\r\n          if (/console\\.|log\\.|logger\\.|debug|info|warn|error/i.test(calledName)) {\r\n            effects.push({ type: 'logging', at: calledName });\r\n          }\r\n          if (/query|execute|find|findOne|save|insert|update|delete|collection|db\\./i.test(calledName)) {\r\n            effects.push({ type: 'database', at: calledName });\r\n          }\r\n          if (/querySelector|getElementById|createElement|appendChild|innerHTML|textContent/i.test(calledName)) {\r\n            effects.push({ type: 'dom', at: calledName });\r\n          }\r\n\r\n          sideEffects.set(funcId, effects);\r\n        }\r\n      }\r\n    });\r\n\r\n    // Build entry\r\n    const calls = callGraph.get(funcId) || [];\r\n    const effects = sideEffects.get(funcId) || [];\r\n    const uniqueCalls = [...new Set(calls)].filter(c => c !== metadata.name);\r\n    const uniqueEffects = effects.reduce((acc, e) => {\r\n      const key = `${e.type}:${e.at}`;\r\n      if (!acc.has(key)) {\r\n        acc.set(key, e);\r\n      }\r\n      return acc;\r\n    }, new Map());\r\n\r\n    // Detect code patterns\r\n    const patterns = [];\r\n    const source = metadata.source || '';\r\n\r\n    // Parsing patterns\r\n    if (calls.some(c => c === 'parse' || c.includes('parse'))) {\r\n      patterns.push({\r\n        type: 'parsing',\r\n        tool: calls.find(c => c.includes('babel') || c.includes('parser')) ? 'babel' : 'unknown',\r\n        description: 'Parses source code into AST'\r\n      });\r\n    }\r\n\r\n    // Hash/crypto patterns\r\n    if (calls.some(c => /hash|md5|sha|digest|crypto/i.test(c))) {\r\n      patterns.push({\r\n        type: 'hashing',\r\n        method: calls.find(c => /md5|sha/i.test(c)) || 'hash',\r\n        description: 'Computes file/content hash for change detection'\r\n      });\r\n    }\r\n\r\n    // Side effect detection patterns\r\n    if (source.includes('/read|write|') || source.includes('/fetch|request|')) {\r\n      patterns.push({\r\n        type: 'side-effect-detection',\r\n        method: 'regex-matching',\r\n        description: 'Detects side effects via regex pattern matching'\r\n      });\r\n    }\r\n\r\n    // Graph manipulation\r\n    if (calls.some(c => /map|filter|reduce|forEach/i.test(c)) &&\r\n        calls.some(c => /graph|entries|functions/i.test(c))) {\r\n      patterns.push({\r\n        type: 'graph-transformation',\r\n        description: 'Transforms or filters call graph data'\r\n      });\r\n    }\r\n\r\n    results.push({\r\n      id: metadata.name,\r\n      type: 'function',\r\n      file: sourcePath,\r\n      line: metadata.line,\r\n      sig: `(${metadata.isAsync ? 'async ' : ''})`,\r\n      async: metadata.isAsync,\r\n      calls: uniqueCalls.slice(0, 10),\r\n      effects: Array.from(uniqueEffects.values()).map(e => e.type),\r\n      patterns: patterns.length > 0 ? patterns : undefined,  // Only include if patterns found\r\n      scipDoc: '',\r\n      functionHash: metadata.hash  // Include for reference\r\n    });\r\n  }\r\n\r\n  return {\r\n    entries: results,\r\n    analysisTime: Date.now() - startTime,\r\n    totalFunctions: allFunctions.length,\r\n    analyzedFunctions: results.length\r\n  };\r\n}"
        },
        "analyzeSingleFile": {
          "hash": "edc3c00dcef24bba3658b8eadd07e0b1",
          "line": 228,
          "endLine": 376,
          "size": 4808,
          "async": false,
          "source": "function analyzeSingleFile(sourcePath) {\r\n  const startTime = Date.now();\r\n  const functions = [];\r\n\r\n  try {\r\n    const source = readFileSync(sourcePath, 'utf-8');\r\n\r\n    // Parse with Babel\r\n    const ast = parse(source, {\r\n      sourceType: 'module',\r\n      plugins: []\r\n    });\r\n\r\n    const callGraph = new Map();\r\n    const sideEffects = new Map();\r\n\r\n    // First pass: collect all functions\r\n    traverse.default(ast, {\r\n      FunctionDeclaration(path) {\r\n        const funcName = path.node.id?.name || 'anonymous';\r\n        const funcId = `${sourcePath}#${funcName}`;\r\n\r\n        functions.push({\r\n          id: funcId,\r\n          name: funcName,\r\n          type: 'function',\r\n          file: sourcePath,\r\n          line: path.node.loc?.start.line || 0,\r\n          params: path.node.params.map(p => p.name || '?').join(', '),\r\n          async: path.node.async,\r\n          path: path\r\n        });\r\n\r\n        callGraph.set(funcId, []);\r\n        sideEffects.set(funcId, []);\r\n      },\r\n\r\n      VariableDeclarator(path) {\r\n        if (path.node.init?.type === 'ArrowFunctionExpression' ||\r\n            path.node.init?.type === 'FunctionExpression') {\r\n          const funcName = path.node.id?.name || 'anonymous';\r\n          const funcId = `${sourcePath}#${funcName}`;\r\n\r\n          functions.push({\r\n            id: funcId,\r\n            name: funcName,\r\n            type: 'function',\r\n            file: sourcePath,\r\n            line: path.node.loc?.start.line || 0,\r\n            params: path.node.init.params.map(p => p.name || '?').join(', '),\r\n            async: path.node.init.async,\r\n            path: path\r\n          });\r\n\r\n          callGraph.set(funcId, []);\r\n          sideEffects.set(funcId, []);\r\n        }\r\n      }\r\n    });\r\n\r\n    // Second pass: analyze each function's body\r\n    functions.forEach(func => {\r\n      if (!func.path) return;\r\n\r\n      const funcId = func.id;\r\n\r\n      func.path.traverse({\r\n        CallExpression(path) {\r\n          const callee = path.node.callee;\r\n          let calledName = '';\r\n\r\n          if (callee.type === 'Identifier') {\r\n            calledName = callee.name;\r\n          } else if (callee.type === 'MemberExpression') {\r\n            const obj = callee.object.name || '';\r\n            const prop = callee.property.name || '';\r\n            calledName = obj ? `${obj}.${prop}` : prop;\r\n          }\r\n\r\n          if (calledName) {\r\n            const calls = callGraph.get(funcId) || [];\r\n            calls.push(calledName);\r\n            callGraph.set(funcId, calls);\r\n\r\n            // Detect side effects\r\n            const effects = sideEffects.get(funcId) || [];\r\n\r\n            if (/read|write|append|unlink|mkdir|rmdir|fs\\./i.test(calledName)) {\r\n              effects.push({ type: 'file_io', at: calledName });\r\n            }\r\n            if (/fetch|request|axios|http|socket/i.test(calledName)) {\r\n              effects.push({ type: 'network', at: calledName });\r\n            }\r\n            if (/console\\.|log\\.|logger\\.|debug|info|warn|error/i.test(calledName)) {\r\n              effects.push({ type: 'logging', at: calledName });\r\n            }\r\n            if (/query|execute|find|findOne|save|insert|update|delete|collection|db\\./i.test(calledName)) {\r\n              effects.push({ type: 'database', at: calledName });\r\n            }\r\n            if (/querySelector|getElementById|createElement|appendChild|innerHTML|textContent/i.test(calledName)) {\r\n              effects.push({ type: 'dom', at: calledName });\r\n            }\r\n\r\n            sideEffects.set(funcId, effects);\r\n          }\r\n        }\r\n      });\r\n\r\n      // Clean up\r\n      delete func.path;\r\n    });\r\n\r\n    // Build output\r\n    const result = functions.map(func => {\r\n      const calls = callGraph.get(func.id) || [];\r\n      const effects = sideEffects.get(func.id) || [];\r\n\r\n      const uniqueCalls = [...new Set(calls)].filter(c => c !== func.name);\r\n      const uniqueEffects = effects.reduce((acc, e) => {\r\n        const key = `${e.type}:${e.at}`;\r\n        if (!acc.has(key)) {\r\n          acc.set(key, e);\r\n        }\r\n        return acc;\r\n      }, new Map());\r\n\r\n      return {\r\n        id: func.name,\r\n        type: func.type,\r\n        file: func.file,\r\n        line: func.line,\r\n        sig: `(${func.params})`,\r\n        async: func.async || false,\r\n        calls: uniqueCalls.slice(0, 10),\r\n        effects: Array.from(uniqueEffects.values()).map(e => e.type),\r\n        scipDoc: ''\r\n      };\r\n    });\r\n\r\n    const analysisTime = Date.now() - startTime;\r\n    console.log(`      Analysis complete: ${functions.length} functions, ${analysisTime}ms`);\r\n\r\n    return { entries: result, analysisTime };\r\n\r\n  } catch (error) {\r\n    console.log(`      Warning: Could not parse ${sourcePath}: ${error.message}`);\r\n    return { entries: [], analysisTime: Date.now() - startTime };\r\n  }\r\n}"
        },
        "loadGraph": {
          "hash": "8521ff896fb3da800c1313f00fe1dcb5",
          "line": 381,
          "endLine": 390,
          "size": 258,
          "async": false,
          "source": "function loadGraph() {\r\n  const graphPath = '.llm-context/graph.jsonl';\r\n\r\n  if (!existsSync(graphPath)) {\r\n    return [];\r\n  }\r\n\r\n  const lines = readFileSync(graphPath, 'utf-8').split('\\n').filter(Boolean);\r\n  return lines.map(line => JSON.parse(line));\r\n}"
        },
        "updateGraphFunctionLevel": {
          "hash": "1ede1a3cd711dfb69336b6d91a8aeaa7",
          "line": 395,
          "endLine": 432,
          "size": 1413,
          "async": false,
          "source": "function updateGraphFunctionLevel(functionChanges, newEntries) {\r\n  console.log('\\n[4] Updating graph.jsonl (function-level)...');\r\n\r\n  const existingEntries = loadGraph();\r\n  console.log(`    Current entries: ${existingEntries.length}`);\r\n\r\n  // Build a set of (file, function) pairs to remove\r\n  const toRemove = new Set();\r\n\r\n  for (const [filePath, changes] of functionChanges) {\r\n    // Remove modified and deleted functions\r\n    for (const func of [...changes.modified, ...changes.deleted]) {\r\n      toRemove.add(`${filePath}#${func.name}`);\r\n    }\r\n  }\r\n\r\n  // Keep entries that aren't in the remove set\r\n  const keptEntries = existingEntries.filter(entry => {\r\n    const key = `${entry.file}#${entry.id}`;\r\n    return !toRemove.has(key);\r\n  });\r\n\r\n  console.log(`    Entries kept (unchanged functions): ${keptEntries.length}`);\r\n  console.log(`    Entries removed (changed/deleted functions): ${existingEntries.length - keptEntries.length}`);\r\n\r\n  // Add new entries\r\n  const updatedGraph = [...keptEntries, ...newEntries];\r\n  console.log(`    New entries added: ${newEntries.length}`);\r\n  console.log(`    Total entries: ${updatedGraph.length}`);\r\n\r\n  // Write updated graph\r\n  const jsonlContent = updatedGraph.map(node => JSON.stringify(node)).join('\\n');\r\n  writeFileSync('.llm-context/graph.jsonl', jsonlContent);\r\n\r\n  console.log('    ✓ Graph updated (function-level)');\r\n\r\n  return updatedGraph;\r\n}"
        },
        "updateGraph": {
          "hash": "14c877494027cea8c9ecc5fc4c98bb75",
          "line": 437,
          "endLine": 464,
          "size": 1116,
          "async": false,
          "source": "function updateGraph(changedFiles, newEntries) {\r\n  console.log('\\n[4] Updating graph.jsonl (file-level)...');\r\n\r\n  // Load existing graph\r\n  const existingEntries = loadGraph();\r\n  console.log(`    Current entries: ${existingEntries.length}`);\r\n\r\n  // Create set of changed files for fast lookup\r\n  const changedSet = new Set(changedFiles);\r\n\r\n  // Keep only entries from unchanged files\r\n  const keptEntries = existingEntries.filter(entry => !changedSet.has(entry.file));\r\n  console.log(`    Entries kept (unchanged files): ${keptEntries.length}`);\r\n  console.log(`    Entries removed (changed files): ${existingEntries.length - keptEntries.length}`);\r\n\r\n  // Add all new entries\r\n  const updatedGraph = [...keptEntries, ...newEntries];\r\n  console.log(`    New entries added: ${newEntries.length}`);\r\n  console.log(`    Total entries: ${updatedGraph.length}`);\r\n\r\n  // Write updated graph\r\n  const jsonlContent = updatedGraph.map(node => JSON.stringify(node)).join('\\n');\r\n  writeFileSync('.llm-context/graph.jsonl', jsonlContent);\r\n\r\n  console.log('    ✓ Graph updated (file-level)');\r\n\r\n  return updatedGraph;\r\n}"
        },
        "updateManifest": {
          "hash": "525b4db9cdd36f6fd07766cda1e8d935",
          "line": 469,
          "endLine": 511,
          "size": 1437,
          "async": false,
          "source": "function updateManifest(changeReport, analysisResults) {\r\n  console.log('\\n[5] Updating manifest.json...');\r\n\r\n  const manifest = changeReport.manifest;\r\n\r\n  // Remove deleted files\r\n  for (const filePath of changeReport.deleted) {\r\n    delete manifest.files[filePath];\r\n    console.log(`    - Removed: ${filePath}`);\r\n  }\r\n\r\n  // Update changed and new files\r\n  const allChangedFiles = [...changeReport.added, ...changeReport.modified];\r\n\r\n  for (const filePath of allChangedFiles) {\r\n    const hash = computeFileHash(filePath);\r\n    const metadata = getFileMetadata(filePath);\r\n    const result = analysisResults.get(filePath);\r\n\r\n    manifest.files[filePath] = {\r\n      hash,\r\n      size: metadata.size,\r\n      lastModified: metadata.lastModified,\r\n      functions: result ? result.entries.map(e => e.id) : [],\r\n      analysisTime: result ? result.analysisTime : null\r\n    };\r\n\r\n    console.log(`    ✓ Updated: ${filePath}`);\r\n  }\r\n\r\n  // Update global stats\r\n  const graph = loadGraph();\r\n  manifest.globalStats.totalFunctions = graph.length;\r\n  manifest.globalStats.totalCalls = graph.reduce((sum, f) => sum + (f.calls?.length || 0), 0);\r\n  manifest.globalStats.totalFiles = Object.keys(manifest.files).length;\r\n  manifest.generated = new Date().toISOString();\r\n\r\n  // Save manifest\r\n  writeFileSync('.llm-context/manifest.json', JSON.stringify(manifest, null, 2));\r\n  console.log('    ✓ Manifest updated');\r\n\r\n  return manifest;\r\n}"
        },
        "mainFunctionLevel": {
          "hash": "a4d7cfedbb46690e84ccb34855fae87f",
          "line": 516,
          "endLine": 631,
          "size": 4219,
          "async": true,
          "source": "async function mainFunctionLevel() {\r\n  console.log('[1] Detecting file-level changes...');\r\n  const changeReport = detectChanges();\r\n\r\n  if (changeReport.needsFullAnalysis) {\r\n    console.log('\\n⚠ No manifest found - run full analysis first');\r\n    return;\r\n  }\r\n\r\n  const changedFiles = [...changeReport.added, ...changeReport.modified];\r\n\r\n  if (changedFiles.length === 0) {\r\n    console.log('\\n✓ No changes detected - all files up to date!');\r\n    return;\r\n  }\r\n\r\n  console.log(`\\n[2] Detecting function-level changes in ${changedFiles.length} files...`);\r\n  const functionChanges = await detectAllFunctionChanges(changedFiles, changeReport.manifest);\r\n\r\n  if (functionChanges.size === 0) {\r\n    console.log('\\n✓ No function-level changes detected!');\r\n    return;\r\n  }\r\n\r\n  printFunctionChangeSummary(functionChanges);\r\n\r\n  // Impact analysis (if enabled)\r\n  const config = loadConfig();\r\n  if (config.analysis?.trackDependencies) {\r\n    const changedFunctionNames = [];\r\n    for (const [filePath, changes] of functionChanges) {\r\n      changedFunctionNames.push(...changes.modified.map(f => f.name));\r\n      changedFunctionNames.push(...changes.added.map(f => f.name));\r\n      if (changes.renames) {\r\n        changedFunctionNames.push(...changes.renames.map(r => r.to));\r\n      }\r\n    }\r\n\r\n    if (changedFunctionNames.length > 0) {\r\n      try {\r\n        analyzeImpact(changedFunctionNames);\r\n      } catch (error) {\r\n        console.log(`\\nWarning: Impact analysis failed: ${error.message}`);\r\n      }\r\n    }\r\n  }\r\n\r\n  console.log('\\n[3] Re-analyzing changed/added functions...');\r\n\r\n  const allNewEntries = [];\r\n  const analysisResults = new Map();\r\n\r\n  for (const [filePath, changes] of functionChanges) {\r\n    // Get names of functions to analyze (modified + added)\r\n    const targetFunctions = [\r\n      ...changes.modified.map(f => f.name),\r\n      ...changes.added.map(f => f.name)\r\n    ];\r\n\r\n    if (targetFunctions.length === 0) {\r\n      continue;\r\n    }\r\n\r\n    console.log(`    ${filePath}: analyzing ${targetFunctions.length} functions`);\r\n\r\n    try {\r\n      const result = analyzeSpecificFunctions(filePath, targetFunctions);\r\n      analysisResults.set(filePath, result);\r\n      allNewEntries.push(...result.entries);\r\n\r\n      console.log(`      Found: ${result.entries.length} entries, ${result.analysisTime}ms`);\r\n      console.log(`      Skipped: ${result.totalFunctions - result.analyzedFunctions} unchanged functions`);\r\n    } catch (error) {\r\n      console.log(`      Error: ${error.message}`);\r\n    }\r\n  }\r\n\r\n  // Update graph (function-level)\r\n  const updatedGraph = updateGraphFunctionLevel(functionChanges, allNewEntries);\r\n\r\n  // Update manifest (note: still need to update function hashes)\r\n  console.log('\\n[5] Updating manifest.json...');\r\n  const manifest = changeReport.manifest;\r\n  const storeSource = config.incremental?.storeSource || false;\r\n\r\n  for (const filePath of changedFiles) {\r\n    const hash = computeFileHash(filePath);\r\n    const metadata = getFileMetadata(filePath);\r\n\r\n    // Re-extract all function hashes for changed files\r\n    const { extractFileFunctions } = await import('./manifest-generator.js');\r\n    const functionHashes = extractFileFunctions(filePath, storeSource);\r\n\r\n    if (manifest.files[filePath]) {\r\n      manifest.files[filePath].hash = hash;\r\n      manifest.files[filePath].size = metadata.size;\r\n      manifest.files[filePath].lastModified = metadata.lastModified;\r\n      manifest.files[filePath].functionHashes = functionHashes;\r\n    }\r\n\r\n    console.log(`    ✓ Updated: ${filePath}`);\r\n  }\r\n\r\n  // Update global stats\r\n  manifest.globalStats.totalFunctions = updatedGraph.length;\r\n  manifest.globalStats.totalCalls = updatedGraph.reduce((sum, f) => sum + (f.calls?.length || 0), 0);\r\n  manifest.generated = new Date().toISOString();\r\n\r\n  writeFileSync('.llm-context/manifest.json', JSON.stringify(manifest, null, 2));\r\n  console.log('    ✓ Manifest updated');\r\n\r\n  console.log('\\n=== Incremental Analysis Complete (Function-Level) ===');\r\n  console.log(`Functions re-analyzed: ${allNewEntries.length}`);\r\n  console.log(`Total functions in graph: ${updatedGraph.length}`);\r\n  console.log(`Total calls tracked: ${manifest.globalStats.totalCalls}`);\r\n}"
        },
        "mainFileLevel": {
          "hash": "bb5f67e9b793f071c5fa527a504a7d5e",
          "line": 636,
          "endLine": 686,
          "size": 2032,
          "async": true,
          "source": "async function mainFileLevel() {\r\n  console.log('[1] Detecting changes...');\r\n  const changeReport = detectChanges();\r\n\r\n  if (changeReport.needsFullAnalysis) {\r\n    console.log('\\n⚠ No manifest found - run full analysis first:');\r\n    console.log('  1. node manifest-generator.js');\r\n    console.log('  2. Ensure graph.jsonl exists');\r\n    console.log('  3. Run this script again');\r\n    return;\r\n  }\r\n\r\n  const changedFiles = [...changeReport.added, ...changeReport.modified];\r\n\r\n  if (changedFiles.length === 0) {\r\n    console.log('\\n✓ No changes detected - all files up to date!');\r\n    return;\r\n  }\r\n\r\n  console.log(`\\n[2] Re-analyzing ${changedFiles.length} changed files...`);\r\n\r\n  const analysisResults = new Map();\r\n  const allNewEntries = [];\r\n\r\n  for (const filePath of changedFiles) {\r\n    console.log(`    Analyzing: ${filePath}`);\r\n    const result = analyzeSingleFile(filePath);\r\n    analysisResults.set(filePath, result);\r\n    allNewEntries.push(...result.entries);\r\n  }\r\n\r\n  console.log(`\\n[3] Summary of re-analysis:`);\r\n  console.log(`    Files analyzed: ${changedFiles.length}`);\r\n  console.log(`    Functions found: ${allNewEntries.length}`);\r\n  console.log(`    Total time: ${Array.from(analysisResults.values()).reduce((sum, r) => sum + r.analysisTime, 0)}ms`);\r\n\r\n  // Update graph\r\n  const updatedGraph = updateGraph(changedFiles, allNewEntries);\r\n\r\n  // Update manifest\r\n  const updatedManifest = updateManifest(changeReport, analysisResults);\r\n\r\n  console.log('\\n=== Incremental Analysis Complete (File-Level) ===');\r\n  console.log(`Files re-analyzed: ${changedFiles.length}`);\r\n  console.log(`Files skipped: ${changeReport.unchanged.length}`);\r\n  console.log(`Total functions in graph: ${updatedGraph.length}`);\r\n  console.log(`Total calls tracked: ${updatedManifest.globalStats.totalCalls}`);\r\n\r\n  const percentSkipped = ((changeReport.unchanged.length / (changedFiles.length + changeReport.unchanged.length)) * 100).toFixed(1);\r\n  console.log(`\\n✓ Efficiency: ${percentSkipped}% of files skipped!`);\r\n}"
        },
        "main": {
          "hash": "dcf93ee7d2cc472d4f67c30d6dac07ab",
          "line": 691,
          "endLine": 702,
          "size": 283,
          "async": true,
          "source": "async function main() {\r\n  const config = loadConfig();\r\n  const granularity = config.granularity || 'file';\r\n\r\n  console.log(`Granularity mode: ${granularity}\\n`);\r\n\r\n  if (granularity === 'function') {\r\n    await mainFunctionLevel();\r\n  } else {\r\n    await mainFileLevel();\r\n  }\r\n}"
        }
      }
    },
    "manifest-generator.js": {
      "hash": "b84e836416754d950f162883df149351",
      "size": 9278,
      "lastModified": "2025-12-02T06:19:36.001Z",
      "functions": [],
      "analysisTime": null,
      "functionHashes": {
        "loadConfig": {
          "hash": "863cd40e998d1eb96353e89dadca18d2",
          "line": 26,
          "endLine": 38,
          "size": 310,
          "async": false,
          "source": "function loadConfig() {\r\n  const configPath = './llm-context.config.json';\r\n\r\n  if (!existsSync(configPath)) {\r\n    // Default config\r\n    return {\r\n      granularity: 'file',\r\n      incremental: { enabled: true, hashAlgorithm: 'md5' }\r\n    };\r\n  }\r\n\r\n  return JSON.parse(readFileSync(configPath, 'utf-8'));\r\n}"
        },
        "computeFileHash": {
          "hash": "b4700116aae3e5fd58d1b945f2ab7428",
          "line": 45,
          "endLine": 48,
          "size": 141,
          "async": false,
          "source": "function computeFileHash(filePath) {\r\n  const content = readFileSync(filePath);\r\n  return createHash('md5').update(content).digest('hex');\r\n}"
        },
        "getFileMetadata": {
          "hash": "033c4d4618e3789932d03e568030b192",
          "line": 55,
          "endLine": 61,
          "size": 162,
          "async": false,
          "source": "function getFileMetadata(filePath) {\r\n  const stats = statSync(filePath);\r\n  return {\r\n    size: stats.size,\r\n    lastModified: stats.mtime.toISOString()\r\n  };\r\n}"
        },
        "extractFileFunctions": {
          "hash": "b9860b18f334af440309246d66dce55d",
          "line": 69,
          "endLine": 128,
          "size": 1724,
          "async": false,
          "source": "function extractFileFunctions(filePath, includeSource = false) {\r\n  const functionMap = {};\r\n\r\n  try {\r\n    const source = readFileSync(filePath, 'utf-8');\r\n\r\n    // Parse with Babel\r\n    const ast = parse(source, {\r\n      sourceType: 'module',\r\n      plugins: []\r\n    });\r\n\r\n    // Collect all functions\r\n    traverse.default(ast, {\r\n      FunctionDeclaration(path) {\r\n        const metadata = extractFunctionMetadata(path, source, filePath);\r\n        const funcEntry = {\r\n          hash: metadata.hash,\r\n          line: metadata.line,\r\n          endLine: metadata.endLine,\r\n          size: metadata.size,\r\n          async: metadata.isAsync\r\n        };\r\n\r\n        // Optionally include source for rename detection and diffs\r\n        if (includeSource) {\r\n          funcEntry.source = metadata.source;\r\n        }\r\n\r\n        functionMap[metadata.name] = funcEntry;\r\n      },\r\n\r\n      VariableDeclarator(path) {\r\n        if (path.node.init?.type === 'ArrowFunctionExpression' ||\r\n            path.node.init?.type === 'FunctionExpression') {\r\n          const metadata = extractFunctionMetadata(path, source, filePath);\r\n          const funcEntry = {\r\n            hash: metadata.hash,\r\n            line: metadata.line,\r\n            endLine: metadata.endLine,\r\n            size: metadata.size,\r\n            async: metadata.isAsync\r\n          };\r\n\r\n          // Optionally include source for rename detection and diffs\r\n          if (includeSource) {\r\n            funcEntry.source = metadata.source;\r\n          }\r\n\r\n          functionMap[metadata.name] = funcEntry;\r\n        }\r\n      }\r\n    });\r\n\r\n  } catch (error) {\r\n    console.log(`    Warning: Could not parse ${filePath}: ${error.message}`);\r\n  }\r\n\r\n  return functionMap;\r\n}"
        },
        "findJsFiles": {
          "hash": "5d9688df93cc3ad11830c7561cb64ad2",
          "line": 136,
          "endLine": 161,
          "size": 707,
          "async": false,
          "source": "function findJsFiles(dir = '.', ignore = ['node_modules', '.git', '.llm-context']) {\r\n  const files = [];\r\n\r\n  function walk(currentDir) {\r\n    const entries = readdirSync(currentDir, { withFileTypes: true });\r\n\r\n    for (const entry of entries) {\r\n      const fullPath = join(currentDir, entry.name);\r\n      const relativePath = relative('.', fullPath);\r\n\r\n      // Skip ignored directories\r\n      if (ignore.some(pattern => relativePath.includes(pattern))) {\r\n        continue;\r\n      }\r\n\r\n      if (entry.isDirectory()) {\r\n        walk(fullPath);\r\n      } else if (entry.isFile() && entry.name.endsWith('.js')) {\r\n        files.push(relativePath);\r\n      }\r\n    }\r\n  }\r\n\r\n  walk(dir);\r\n  return files;\r\n}"
        },
        "walk": {
          "hash": "096254dcdbe490ad48df089e1272a85a",
          "line": 139,
          "endLine": 157,
          "size": 560,
          "async": false,
          "source": "function walk(currentDir) {\r\n    const entries = readdirSync(currentDir, { withFileTypes: true });\r\n\r\n    for (const entry of entries) {\r\n      const fullPath = join(currentDir, entry.name);\r\n      const relativePath = relative('.', fullPath);\r\n\r\n      // Skip ignored directories\r\n      if (ignore.some(pattern => relativePath.includes(pattern))) {\r\n        continue;\r\n      }\r\n\r\n      if (entry.isDirectory()) {\r\n        walk(fullPath);\r\n      } else if (entry.isFile() && entry.name.endsWith('.js')) {\r\n        files.push(relativePath);\r\n      }\r\n    }\r\n  }"
        },
        "loadGraphData": {
          "hash": "e5f8ab5b7def01c329e4f2c5478a6ad8",
          "line": 167,
          "endLine": 190,
          "size": 632,
          "async": false,
          "source": "function loadGraphData() {\r\n  const graphPath = '.llm-context/graph.jsonl';\r\n  const fileToFunctions = new Map();\r\n\r\n  if (!existsSync(graphPath)) {\r\n    console.log('No existing graph.jsonl found - this will be the initial analysis');\r\n    return fileToFunctions;\r\n  }\r\n\r\n  const lines = readFileSync(graphPath, 'utf-8').split('\\n').filter(Boolean);\r\n\r\n  for (const line of lines) {\r\n    const func = JSON.parse(line);\r\n    const file = func.file;\r\n\r\n    if (!fileToFunctions.has(file)) {\r\n      fileToFunctions.set(file, []);\r\n    }\r\n\r\n    fileToFunctions.get(file).push(func.id || func.name);\r\n  }\r\n\r\n  return fileToFunctions;\r\n}"
        },
        "generateManifest": {
          "hash": "ea9a1ce533d8da5356e0f3c712920d43",
          "line": 196,
          "endLine": 284,
          "size": 3029,
          "async": false,
          "source": "function generateManifest() {\r\n  const config = loadConfig();\r\n  const granularity = config.granularity || 'file';\r\n\r\n  console.log(`[1] Configuration: granularity=${granularity}`);\r\n  console.log('[2] Discovering JavaScript files...');\r\n  const jsFiles = findJsFiles();\r\n  console.log(`    Found ${jsFiles.length} JavaScript files\\n`);\r\n\r\n  console.log('[3] Computing file hashes...');\r\n  const fileToFunctions = loadGraphData();\r\n  const files = {};\r\n  let totalSize = 0;\r\n\r\n  for (const filePath of jsFiles) {\r\n    try {\r\n      const hash = computeFileHash(filePath);\r\n      const metadata = getFileMetadata(filePath);\r\n      const graphFunctions = fileToFunctions.get(filePath) || [];\r\n\r\n      const fileEntry = {\r\n        hash,\r\n        size: metadata.size,\r\n        lastModified: metadata.lastModified,\r\n        functions: graphFunctions,\r\n        analysisTime: null\r\n      };\r\n\r\n      // Add function-level hashes if granularity is 'function'\r\n      if (granularity === 'function') {\r\n        const storeSource = config.incremental?.storeSource || false;\r\n        const functionMetadata = extractFileFunctions(filePath, storeSource);\r\n        fileEntry.functionHashes = functionMetadata;\r\n\r\n        console.log(`    ${filePath}`);\r\n        console.log(`      File hash: ${hash.substring(0, 12)}...`);\r\n        console.log(`      Functions: ${Object.keys(functionMetadata).length}`);\r\n\r\n        // Show first few function hashes\r\n        const funcNames = Object.keys(functionMetadata).slice(0, 3);\r\n        for (const name of funcNames) {\r\n          const fHash = functionMetadata[name].hash.substring(0, 8);\r\n          console.log(`        - ${name} (${fHash}...)`);\r\n        }\r\n        if (Object.keys(functionMetadata).length > 3) {\r\n          console.log(`        ... and ${Object.keys(functionMetadata).length - 3} more`);\r\n        }\r\n      } else {\r\n        console.log(`    ${filePath}`);\r\n        console.log(`      Hash: ${hash.substring(0, 12)}...`);\r\n        console.log(`      Functions: ${graphFunctions.length > 0 ? graphFunctions.join(', ') : 'none yet'}`);\r\n      }\r\n\r\n      files[filePath] = fileEntry;\r\n      totalSize += metadata.size;\r\n\r\n    } catch (error) {\r\n      console.log(`    Warning: Could not process ${filePath}: ${error.message}`);\r\n    }\r\n  }\r\n\r\n  console.log(`\\n[4] Building manifest...`);\r\n\r\n  // Load global stats from graph if available\r\n  let globalStats = {\r\n    totalFunctions: 0,\r\n    totalCalls: 0,\r\n    totalFiles: jsFiles.length,\r\n    totalSize\r\n  };\r\n\r\n  if (existsSync('.llm-context/graph.jsonl')) {\r\n    const lines = readFileSync('.llm-context/graph.jsonl', 'utf-8').split('\\n').filter(Boolean);\r\n    const functions = lines.map(line => JSON.parse(line));\r\n\r\n    globalStats.totalFunctions = functions.length;\r\n    globalStats.totalCalls = functions.reduce((sum, f) => sum + (f.calls?.length || 0), 0);\r\n  }\r\n\r\n  const manifest = {\r\n    version: '2.0.0',\r\n    granularity,\r\n    generated: new Date().toISOString(),\r\n    files,\r\n    globalStats\r\n  };\r\n\r\n  return manifest;\r\n}"
        },
        "saveManifest": {
          "hash": "71f667bdb45a3714724a9f87aecdacf1",
          "line": 290,
          "endLine": 302,
          "size": 637,
          "async": false,
          "source": "function saveManifest(manifest) {\r\n  const manifestPath = '.llm-context/manifest.json';\r\n  writeFileSync(manifestPath, JSON.stringify(manifest, null, 2));\r\n  console.log(`\\n✓ Manifest saved to ${manifestPath}`);\r\n\r\n  // Print summary\r\n  console.log('\\n=== Manifest Summary ===');\r\n  console.log(`Files tracked: ${Object.keys(manifest.files).length}`);\r\n  console.log(`Total size: ${(manifest.globalStats.totalSize / 1024).toFixed(1)} KB`);\r\n  console.log(`Functions: ${manifest.globalStats.totalFunctions}`);\r\n  console.log(`Call relationships: ${manifest.globalStats.totalCalls}`);\r\n  console.log(`Generated: ${manifest.generated}`);\r\n}"
        },
        "main": {
          "hash": "31e20048d05396d5fda09fc71ce58988",
          "line": 307,
          "endLine": 310,
          "size": 87,
          "async": false,
          "source": "function main() {\r\n  const manifest = generateManifest();\r\n  saveManifest(manifest);\r\n}"
        }
      }
    },
    "query.js": {
      "hash": "33d36537181105026b872c30b8b79c0c",
      "size": 5288,
      "lastModified": "2026-01-09T05:19:16.930Z",
      "functions": [
        "query",
        "traceCalls"
      ],
      "analysisTime": null,
      "functionHashes": {
        "query": {
          "hash": "cde8c41e24b6c4b4b78ac7720ee03617",
          "line": 52,
          "endLine": 94,
          "size": 1340,
          "async": false,
          "source": "function query(cmd, arg) {\r\n  switch (cmd) {\r\n    case 'find-function':\r\n      return Array.from(byName.get(arg) || []);\r\n\r\n    case 'functions-in-file':\r\n      return byFile.get(arg) || [];\r\n\r\n    case 'calls-to':\r\n      return Array.from(calledByIndex.get(arg) || []);\r\n\r\n    case 'called-by':\r\n      const func = functions.find(f => (f.name || f.id) === arg);\r\n      return func ? func.calls : [];\r\n\r\n    case 'side-effects':\r\n      return functions.filter(f => f.effects.length > 0);\r\n\r\n    case 'entry-points':\r\n      // Functions called by few others (likely entry points)\r\n      return functions.filter(f => {\r\n        const name = f.name || f.id;\r\n        const callers = calledByIndex.get(name) || new Set();\r\n        return callers.size === 0 || f.name?.includes('main') || f.name?.includes('init');\r\n      });\r\n\r\n    case 'trace':\r\n      // Trace call path from function\r\n      return traceCalls(arg, 3);\r\n\r\n    case 'stats':\r\n      return {\r\n        totalFunctions: functions.length,\r\n        filesAnalyzed: byFile.size,\r\n        totalCalls: functions.reduce((sum, f) => sum + f.calls.length, 0),\r\n        withSideEffects: functions.filter(f => f.effects.length > 0).length,\r\n        effectTypes: [...new Set(functions.flatMap(f => f.effects))]\r\n      };\r\n\r\n    default:\r\n      return { error: 'Unknown query command' };\r\n  }\r\n}"
        },
        "traceCalls": {
          "hash": "1126a12ebf837e5f8c7e6dff92cdcd54",
          "line": 96,
          "endLine": 110,
          "size": 440,
          "async": false,
          "source": "function traceCalls(funcName, depth = 3, visited = new Set()) {\r\n  if (depth === 0 || visited.has(funcName)) return [];\r\n\r\n  visited.add(funcName);\r\n\r\n  const func = functions.find(f => (f.name || f.id) === funcName);\r\n  if (!func) return [];\r\n\r\n  return {\r\n    function: funcName,\r\n    file: func.file,\r\n    line: func.line,\r\n    calls: func.calls.slice(0, 10).map(called => traceCalls(called, depth - 1, visited)).filter(Boolean)\r\n  };\r\n}"
        }
      }
    },
    "scip-parser.js": {
      "hash": "1d92669c1d83375a50e12ff550d09f9f",
      "size": 6186,
      "lastModified": "2025-11-09T11:43:50.718Z",
      "functions": [
        "parseScip"
      ],
      "analysisTime": null,
      "functionHashes": {
        "parseScip": {
          "hash": "7361e522e6d5a944f7e465d87f9ef0f6",
          "line": 12,
          "endLine": 196,
          "size": 5917,
          "async": true,
          "source": "async function parseScip() {\n  try {\n    // Load the protobuf schema\n    const root = await protobuf.load(protoFile);\n    const Index = root.lookupType('scip.Index');\n\n    // Read and decode the SCIP file\n    const buffer = readFileSync(scipFile);\n    const index = Index.decode(buffer);\n\n    const indexObj = Index.toObject(index, {\n      longs: String,\n      enums: String,\n      bytes: String,\n    });\n\n    console.log('=== SCIP Index Summary ===\\n');\n\n    const metadata = indexObj.metadata || {};\n    console.log('Metadata:');\n    console.log('  Tool:', metadata.toolInfo?.name || 'N/A', metadata.toolInfo?.version || '');\n    console.log('  Project Root:', metadata.projectRoot || 'N/A');\n\n    const documents = indexObj.documents || [];\n    console.log('\\nDocuments indexed:', documents.length);\n\n    // Group files by directory\n    const byDir = {};\n    documents.forEach(doc => {\n      const dir = doc.relativePath.split('/').slice(0, -1).join('/') || '.';\n      byDir[dir] = (byDir[dir] || 0) + 1;\n    });\n\n    console.log('\\nFiles by directory:');\n    Object.entries(byDir).slice(0, 10).forEach(([dir, count]) => {\n      console.log(`  ${dir}: ${count} files`);\n    });\n\n    // Analyze first few documents in detail\n    console.log('\\n=== Sample Documents (first 3) ===\\n');\n\n    documents.slice(0, 3).forEach((doc, idx) => {\n      console.log(`\\n[${idx + 1}] ${doc.relativePath}`);\n      console.log(`    Language: ${doc.language || 'unknown'}`);\n\n      const occurrences = doc.occurrences || [];\n      const symbols = doc.symbols || [];\n\n      console.log(`    Occurrences: ${occurrences.length}`);\n      console.log(`    Symbols defined: ${symbols.length}`);\n\n      // Show first few symbols\n      if (symbols.length > 0) {\n        console.log('\\n    Symbol Details:');\n        symbols.slice(0, 5).forEach(sym => {\n          const symStr = sym.symbol || '';\n          const kind = sym.kind || 0;\n          const docs = sym.documentation || [];\n          const sig = sym.signatureDocumentation?.text || '';\n\n          // Parse symbol to get just the name\n          const parts = symStr.split('/');\n          const name = parts[parts.length - 1]?.replace(/[.`]/g, '') || symStr;\n\n          const kindNames = {\n            1: 'Unknown',\n            6: 'Class',\n            8: 'Method',\n            9: 'Function',\n            10: 'Property',\n            12: 'Variable',\n          };\n\n          console.log(`      - ${name}`);\n          console.log(`        Kind: ${kindNames[kind] || kind}`);\n          if (sig) {\n            console.log(`        Sig: ${sig.substring(0, 60)}${sig.length > 60 ? '...' : ''}`);\n          }\n          if (docs.length > 0) {\n            const docText = docs[0];\n            console.log(`        Doc: ${docText.substring(0, 60)}${docText.length > 60 ? '...' : ''}`);\n          }\n        });\n      }\n\n      // Show sample occurrences (function calls/references)\n      if (occurrences.length > 0) {\n        console.log('\\n    Sample Occurrences (first 5):');\n        occurrences.slice(0, 5).forEach(occ => {\n          const range = occ.range || [];\n          const symbol = occ.symbol || '';\n          const roles = occ.symbolRoles || 0;\n\n          // Parse symbol to get readable name\n          const parts = symbol.split('/');\n          const name = parts[parts.length - 1]?.replace(/[.`]/g, '') || symbol;\n\n          const roleNames = {\n            1: 'Definition',\n            2: 'Import',\n            4: 'Reference',\n            8: 'WriteAccess',\n            16: 'ReadAccess',\n          };\n\n          console.log(`      - ${name}`);\n          console.log(`        Line: ${range[0] || 0}, Roles: ${roleNames[roles] || roles}`);\n        });\n      }\n    });\n\n    // Global statistics\n    console.log('\\n\\n=== Global Statistics ===\\n');\n\n    let totalOccurrences = 0;\n    let totalSymbols = 0;\n    let symbolsByKind = {};\n    let functionSymbols = [];\n\n    documents.forEach(doc => {\n      const symbols = doc.symbols || [];\n      const occurrences = doc.occurrences || [];\n\n      totalSymbols += symbols.length;\n      totalOccurrences += occurrences.length;\n\n      symbols.forEach(sym => {\n        const kind = sym.kind || 0;\n        symbolsByKind[kind] = (symbolsByKind[kind] || 0) + 1;\n\n        // Collect function symbols for later analysis\n        if (kind === 9 || kind === 8) { // Function or Method\n          functionSymbols.push({\n            name: sym.symbol,\n            file: doc.relativePath,\n            sig: sym.signatureDocumentation?.text || '',\n            doc: (sym.documentation || [])[0] || ''\n          });\n        }\n      });\n    });\n\n    console.log('Total Symbols:', totalSymbols);\n    console.log('Total Occurrences:', totalOccurrences);\n    console.log('\\nSymbols by Kind:');\n\n    const kindNames = {\n      1: 'Unknown',\n      2: 'Namespace',\n      3: 'Type',\n      6: 'Class',\n      8: 'Method',\n      9: 'Function',\n      10: 'Property',\n      12: 'Variable',\n      13: 'Constant',\n    };\n\n    Object.entries(symbolsByKind)\n      .sort((a, b) => b[1] - a[1])\n      .forEach(([kind, count]) => {\n        console.log(`  ${kindNames[kind] || kind}: ${count}`);\n      });\n\n    console.log('\\nFunctions/Methods found:', functionSymbols.length);\n    console.log('Sample functions:');\n    functionSymbols.slice(0, 10).forEach(fn => {\n      const name = fn.name.split('/').pop().replace(/[.`]/g, '');\n      console.log(`  ${name} (${fn.file})`);\n      if (fn.sig) {\n        console.log(`    Signature: ${fn.sig.substring(0, 70)}`);\n      }\n    });\n\n    // Save full data for transformer\n    console.log('\\n\\n=== Saving parsed data for transformer ===');\n    const fs = await import('fs');\n    fs.writeFileSync('.llm-context/scip-parsed.json', JSON.stringify(indexObj, null, 2));\n    console.log('Saved to .llm-context/scip-parsed.json');\n\n  } catch (error) {\n    console.error('Error parsing SCIP file:', error.message);\n    console.error(error.stack);\n  }\n}"
        }
      }
    },
    "summarizer.js": {
      "hash": "990665808eb90cda16fab23038eff062",
      "size": 6667,
      "lastModified": "2025-11-09T11:43:50.719Z",
      "functions": [],
      "analysisTime": null,
      "functionHashes": {}
    },
    "summary-updater.js": {
      "hash": "67b0b3abab7c7fdedce788f013d3e5c8",
      "size": 10683,
      "lastModified": "2026-01-09T05:17:51.983Z",
      "functions": [
        "loadGraph",
        "generateL0",
        "generateL1",
        "generateL2",
        "updateSummaries"
      ],
      "analysisTime": null,
      "functionHashes": {
        "loadGraph": {
          "hash": "54d9c211ef2a5e1f97c1792c80338c85",
          "line": 22,
          "endLine": 31,
          "size": 300,
          "async": false,
          "source": "function loadGraph() {\r\n  const graphPath = '.llm-context/graph.jsonl';\r\n  if (!existsSync(graphPath)) {\r\n    console.log('⚠ No graph.jsonl found');\r\n    return [];\r\n  }\r\n\r\n  const lines = readFileSync(graphPath, 'utf-8').split('\\n').filter(Boolean);\r\n  return lines.map(line => JSON.parse(line));\r\n}"
        },
        "generateL0": {
          "hash": "2778144efb2ee709fe5c8731639421af",
          "line": 36,
          "endLine": 128,
          "size": 3086,
          "async": false,
          "source": "function generateL0(functions) {\r\n  console.log('[1] Generating L0 (system overview)...');\r\n\r\n  // Group by file\r\n  const byFile = {};\r\n  functions.forEach(func => {\r\n    if (!byFile[func.file]) byFile[func.file] = [];\r\n    byFile[func.file].push(func);\r\n  });\r\n\r\n  // Group by domain (directory)\r\n  const byDomain = {};\r\n  Object.keys(byFile).forEach(file => {\r\n    const dir = dirname(file) || 'root';\r\n    if (!byDomain[dir]) byDomain[dir] = {};\r\n\r\n    const module = file.split('/').pop().replace('.js', '');\r\n    byDomain[dir][module] = byFile[file];\r\n  });\r\n\r\n  const totalFuncs = functions.length;\r\n  const totalCalls = functions.reduce((sum, f) => sum + f.calls.length, 0);\r\n  const effectTypes = new Set();\r\n  functions.forEach(f => f.effects.forEach(e => effectTypes.add(e)));\r\n\r\n  const entryPoints = functions.filter(f =>\r\n    f.name && (\r\n      f.name.includes('main') ||\r\n      f.name.includes('init') ||\r\n      f.name.includes('eval')\r\n    )\r\n  );\r\n\r\n  const L0 = `# LLM Context Tools - System Overview\r\n\r\n**Type**: Code analysis system for LLM-optimized context generation\r\n**Purpose**: Generate compact, semantically-rich code representations for LLM consumption\r\n**Architecture**: JavaScript modules with incremental update support\r\n\r\n## ⚡ Quick Queries (USE THESE before grep/read)\r\n\r\n**To understand this codebase, try these queries FIRST:**\r\n\r\n\\`\\`\\`bash\r\n# Find any function\r\nllm-context query find-function <name>\r\n\r\n# Understand dependencies\r\nllm-context query calls-to <name>      # Who calls this?\r\nllm-context query trace <name>         # Full call tree\r\n\r\n# Discover patterns\r\nllm-context entry-points               # ${entryPoints.length} entry points\r\nllm-context side-effects               # Functions with I/O\r\n\r\n# Statistics\r\nllm-context stats                      # Full statistics\r\n\\`\\`\\`\r\n\r\n**Why queries > grep:**\r\n- ✅ Show call relationships (grep can't)\r\n- ✅ Detect side effects (grep misses these)\r\n- ✅ Trace call trees (grep shows only text matches)\r\n- ✅ 80-95% fewer tokens needed\r\n\r\n## Statistics\r\n- **Files**: ${Object.keys(byFile).length} modules\r\n- **Functions**: ${totalFuncs} total\r\n- **Call relationships**: ${totalCalls}\r\n- **Side effects**: ${Array.from(effectTypes).join(', ') || 'none'}\r\n\r\n## Key Components\r\n${Object.keys(byDomain).map(domain => {\r\n  const modules = Object.keys(byDomain[domain]);\r\n  return `- **${domain}**: ${modules.join(', ')}`;\r\n}).join('\\n')}\r\n\r\n## Entry Points\r\n${entryPoints.length > 0 ? entryPoints.slice(0, 5).map(f => `- \\`${f.name}\\` (${f.file}:${f.line})`).join('\\n') : '- None detected'}\r\n\r\n## Architecture Pattern\r\n- **Manifest System**: Tracks file hashes for change detection\r\n- **Incremental Analysis**: Re-analyze only changed files\r\n- **Graph Management**: JSONL format for efficient updates\r\n- **Query Interface**: Fast lookups on function call graphs\r\n`;\r\n\r\n  mkdirSync('.llm-context/summaries', { recursive: true });\r\n  writeFileSync('.llm-context/summaries/L0-system.md', L0);\r\n  console.log(`    ✓ L0-system.md (${L0.length} chars, ~${Math.ceil(L0.length / 4)} tokens)`);\r\n\r\n  return L0;\r\n}"
        },
        "generateL1": {
          "hash": "484234fdea30d0ab77a216eaf3365589",
          "line": 133,
          "endLine": 216,
          "size": 2685,
          "async": false,
          "source": "function generateL1(functions, changedFiles = null) {\r\n  console.log('[2] Generating L1 (domain summaries)...');\r\n\r\n  // Group by file\r\n  const byFile = {};\r\n  functions.forEach(func => {\r\n    if (!byFile[func.file]) byFile[func.file] = [];\r\n    byFile[func.file].push(func);\r\n  });\r\n\r\n  // Group by domain\r\n  const byDomain = {};\r\n  Object.keys(byFile).forEach(file => {\r\n    const dir = dirname(file) || 'root';\r\n    const module = file.split('/').pop().replace('.js', '');\r\n\r\n    if (!byDomain[dir]) byDomain[dir] = {};\r\n    byDomain[dir][module] = byFile[file];\r\n  });\r\n\r\n  // Load existing L1 if available\r\n  let existingL1 = [];\r\n  if (existsSync('.llm-context/summaries/L1-domains.json')) {\r\n    existingL1 = JSON.parse(readFileSync('.llm-context/summaries/L1-domains.json', 'utf-8'));\r\n  }\r\n\r\n  // Determine which domains were affected\r\n  const affectedDomains = new Set();\r\n  if (changedFiles) {\r\n    changedFiles.forEach(file => {\r\n      const dir = dirname(file) || 'root';\r\n      affectedDomains.add(dir);\r\n    });\r\n  } else {\r\n    // If no changed files specified, regenerate all\r\n    Object.keys(byDomain).forEach(dir => affectedDomains.add(dir));\r\n  }\r\n\r\n  console.log(`    Affected domains: ${Array.from(affectedDomains).join(', ')}`);\r\n\r\n  // Build L1 summaries\r\n  const L1Summaries = [];\r\n\r\n  // Keep existing summaries for unchanged domains\r\n  if (changedFiles) {\r\n    existingL1.forEach(summary => {\r\n      if (!affectedDomains.has(summary.domain)) {\r\n        L1Summaries.push(summary);\r\n        console.log(`    ↻ Kept: ${summary.domain} (unchanged)`);\r\n      }\r\n    });\r\n  }\r\n\r\n  // Generate summaries for affected domains\r\n  Object.entries(byDomain).forEach(([domain, modules]) => {\r\n    if (!affectedDomains.has(domain) && changedFiles) return;\r\n\r\n    const domainFuncs = Object.values(modules).flat();\r\n    const funcCount = domainFuncs.length;\r\n    const moduleList = Object.keys(modules);\r\n\r\n    const domainEffects = new Set();\r\n    domainFuncs.forEach(f => f.effects.forEach(e => domainEffects.add(e)));\r\n\r\n    const summary = {\r\n      domain,\r\n      modules: moduleList,\r\n      functionCount: funcCount,\r\n      effects: Array.from(domainEffects),\r\n      keyFunctions: domainFuncs\r\n        .filter(f => f.calls.length > 3 || f.effects.length > 0)\r\n        .slice(0, 5)\r\n        .map(f => ({ name: f.name, file: f.file, line: f.line }))\r\n    };\r\n\r\n    L1Summaries.push(summary);\r\n    console.log(`    ✓ Updated: ${domain} (${funcCount} functions)`);\r\n  });\r\n\r\n  writeFileSync('.llm-context/summaries/L1-domains.json', JSON.stringify(L1Summaries, null, 2));\r\n  console.log(`    ✓ L1-domains.json (${L1Summaries.length} domains)`);\r\n\r\n  return L1Summaries;\r\n}"
        },
        "generateL2": {
          "hash": "e70b198e3a1640d0136a606509a31d84",
          "line": 221,
          "endLine": 286,
          "size": 2110,
          "async": false,
          "source": "function generateL2(functions, changedFiles = null) {\r\n  console.log('[3] Generating L2 (module summaries)...');\r\n\r\n  // Group by file\r\n  const byFile = {};\r\n  functions.forEach(func => {\r\n    if (!byFile[func.file]) byFile[func.file] = [];\r\n    byFile[func.file].push(func);\r\n  });\r\n\r\n  // Load existing L2 if available\r\n  let existingL2 = [];\r\n  if (existsSync('.llm-context/summaries/L2-modules.json')) {\r\n    existingL2 = JSON.parse(readFileSync('.llm-context/summaries/L2-modules.json', 'utf-8'));\r\n  }\r\n\r\n  // Determine which files were affected\r\n  const affectedFiles = changedFiles ? new Set(changedFiles) : new Set(Object.keys(byFile));\r\n\r\n  console.log(`    Affected modules: ${affectedFiles.size}`);\r\n\r\n  const L2Summaries = [];\r\n\r\n  // Keep existing summaries for unchanged files\r\n  if (changedFiles) {\r\n    existingL2.forEach(summary => {\r\n      if (!affectedFiles.has(summary.file)) {\r\n        L2Summaries.push(summary);\r\n        console.log(`    ↻ Kept: ${summary.module} (unchanged)`);\r\n      }\r\n    });\r\n  }\r\n\r\n  // Generate summaries for affected files\r\n  Object.entries(byFile).forEach(([file, funcs]) => {\r\n    if (!affectedFiles.has(file) && changedFiles) return;\r\n\r\n    const module = file.split('/').pop().replace('.js', '');\r\n    const exports = funcs.filter(f => f.calls.length > 5);\r\n    const effects = new Set();\r\n    funcs.forEach(f => f.effects.forEach(e => effects.add(e)));\r\n\r\n    const summary = {\r\n      file,\r\n      module,\r\n      functionCount: funcs.length,\r\n      exports: exports.map(f => f.name),\r\n      effects: Array.from(effects),\r\n      entryPoints: funcs\r\n        .filter(f => f.name && (\r\n          f.name.includes('main') ||\r\n          f.name.includes('process') ||\r\n          f.name.includes('init')\r\n        ))\r\n        .map(f => f.name)\r\n    };\r\n\r\n    L2Summaries.push(summary);\r\n    console.log(`    ✓ Updated: ${module} (${funcs.length} functions)`);\r\n  });\r\n\r\n  writeFileSync('.llm-context/summaries/L2-modules.json', JSON.stringify(L2Summaries, null, 2));\r\n  console.log(`    ✓ L2-modules.json (${L2Summaries.length} modules)`);\r\n\r\n  return L2Summaries;\r\n}"
        },
        "updateSummaries": {
          "hash": "c6f949f4c669f04bd048ab3fa691da69",
          "line": 292,
          "endLine": 325,
          "size": 1184,
          "async": false,
          "source": "function updateSummaries(changedFiles = null) {\r\n  const functions = loadGraph();\r\n\r\n  if (functions.length === 0) {\r\n    console.log('⚠ No functions in graph - nothing to summarize');\r\n    return;\r\n  }\r\n\r\n  console.log(`Loaded ${functions.length} functions from graph\\n`);\r\n\r\n  if (changedFiles && changedFiles.length > 0) {\r\n    console.log(`Incremental mode: ${changedFiles.length} files changed`);\r\n    console.log(`Changed files: ${changedFiles.join(', ')}\\n`);\r\n  } else {\r\n    console.log('Full regeneration mode\\n');\r\n  }\r\n\r\n  const L0 = generateL0(functions);\r\n  const L1 = generateL1(functions, changedFiles);\r\n  const L2 = generateL2(functions, changedFiles);\r\n\r\n  console.log('\\n=== Summary Update Complete ===');\r\n  console.log('Generated:');\r\n  console.log('  - L0-system.md');\r\n  console.log('  - L1-domains.json');\r\n  console.log('  - L2-modules.json');\r\n\r\n  if (changedFiles && changedFiles.length > 0) {\r\n    const domainsUpdated = new Set(changedFiles.map(f => dirname(f) || 'root')).size;\r\n    console.log(`\\nEfficiency:`);\r\n    console.log(`  - Domains regenerated: ${domainsUpdated}`);\r\n    console.log(`  - Modules regenerated: ${changedFiles.length}`);\r\n  }\r\n}"
        }
      }
    },
    "transformer.js": {
      "hash": "fd75b4a2567e0044a0f178464d941828",
      "size": 9079,
      "lastModified": "2025-11-09T11:43:50.721Z",
      "functions": [],
      "analysisTime": null,
      "functionHashes": {}
    }
  },
  "globalStats": {
    "totalFunctions": 28,
    "totalCalls": 187,
    "totalFiles": 13,
    "totalSize": 105919
  }
}